{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Uses the Tensoflow machine learning library to train the Poisson \n",
    "autoencoder inverting network (PAIN) to reconstruct compressed \n",
    "MNIST images with Poisson noise, and saves the trained model.\n",
    "\n",
    "Authors: Fabian Santiago\n",
    "Last Update: August 18, 2024\n",
    "'''\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.util.shape import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for TensorFlow and Keras\n",
    "tf.random.set_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sliding window compression\n",
    "def median_downsampling(in_image, cmp_dim):\n",
    "    if cmp_dim < 15:\n",
    "        # Compression dimension to window size\n",
    "        window_size = 28//cmp_dim\n",
    "        # Create sliding windows\n",
    "        windows = view_as_windows(in_image, (window_size, window_size), step=window_size)\n",
    "        # Calculate the median over each window\n",
    "        return np.median(windows, axis=(2, 3))\n",
    "    else:\n",
    "        return in_image\n",
    "\n",
    "# Define compression of entries in an array\n",
    "def down_sample_list(in_array,cmp_dim):\n",
    "    out_array = np.empty((len(in_array), cmp_dim, cmp_dim))\n",
    "    \n",
    "    # Iterate over array\n",
    "    for idx, image in enumerate(in_array):\n",
    "        out_array[idx] = median_downsampling(image,cmp_dim)\n",
    "        \n",
    "    # Return array containing compressed entries \n",
    "    return out_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST Dataset\n",
    "########################\n",
    "# Dimension of the compressed/noisy images (width=height)  \n",
    "# cmp_dim = 4:(for 4x4), 7:(7x7), 14:(14x14), or 28:(28x284)\n",
    "cmp_dim = 7\n",
    "\n",
    "# Dimension of output, original are 28 x 28\n",
    "out_dim  = 28 \n",
    "\n",
    "# Load MNIST\n",
    "(clean_train, _), (clean_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Step 1: Compress images using median in sliding window\n",
    "cmp_train = down_sample_list(clean_train, cmp_dim)\n",
    "cmp_test  = down_sample_list(clean_test, cmp_dim)\n",
    "\n",
    "# Step 2: Add Poisson noise to compressed images\n",
    "noisy_train_ = np.random.poisson(lam=cmp_train)\n",
    "noisy_test_  = np.random.poisson(lam=cmp_test)\n",
    "noisy_train  = np.clip(noisy_train_,0,255)\n",
    "noisy_test   = np.clip(noisy_test_,0,255)\n",
    "\n",
    "# Step 3: Reshape Input Arrays\n",
    "noisy_train = np.array([matrix.reshape(cmp_dim**2,) for matrix in noisy_train/255])\n",
    "noisy_test  = np.array([matrix.reshape(cmp_dim**2,) for matrix in noisy_test/255])\n",
    "\n",
    "# Step 4: Reshape Expected Ouput Arraus\n",
    "clean_train = np.array([matrix.reshape(28**2,) for matrix in clean_train/255])\n",
    "clean_test  = np.array([matrix.reshape(28**2,) for matrix in clean_test/255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Poisson autoencoder inverting network (PAIN)\n",
    "####################################################\n",
    "\n",
    "# Define model architecture\n",
    "def build_PAIN(in_dim, out_dim, enc_dim = 256):\n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=(in_dim**2,))\n",
    "\n",
    "    # First Decoder\n",
    "    Dec1 = tf.keras.layers.Dense(out_dim**2, activation='sigmoid')(inputs)\n",
    "\n",
    "    # Encoder\n",
    "    Enc2_hidden = tf.keras.layers.Dense(enc_dim, activation='sigmoid')(Dec1)\n",
    "    Enc2 = tf.keras.layers.Dense(in_dim**2, activation='sigmoid')(Enc2_hidden)\n",
    "\n",
    "    # Second Decoder\n",
    "    Dec2_hidden = tf.keras.layers.Dense(enc_dim, activation='sigmoid')(Enc2)\n",
    "    outputs = tf.keras.layers.Dense(out_dim**2, activation='sigmoid')(Dec2_hidden)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & Compile the PAIN model\n",
    "PAIN = build_PAIN(in_dim=cmp_dim, out_dim=out_dim)\n",
    "\n",
    "# Create an RMSProp optimizer with a specific learning rate\n",
    "RMSp = tf.keras.optimizers.RMSprop(learning_rate=0.05)\n",
    "\n",
    "# Compile the model\n",
    "PAIN.compile(optimizer=RMSp, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model saving fitting history\n",
    "fit_history = PAIN.fit(noisy_train, clean_train, epochs=250, batch_size=250,validation_data=(noisy_test, clean_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save training and validation loss\n",
    "# ###################################\n",
    "\n",
    "# # Model directory \n",
    "# directory = \"TrainLoss\"\n",
    "\n",
    "# # If directory does not exist, create it\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "    \n",
    "# # Get training loss values\n",
    "# loss_values = fit_history.history['loss']\n",
    "\n",
    "# # Get validation loss values\n",
    "# val_loss_values = fit_history.history.get('val_loss')\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'epoch': range(1, len(loss_values) + 1),\n",
    "#     'loss': loss_values,\n",
    "#     'val_loss': val_loss_values\n",
    "# })\n",
    "# df.to_csv(f'TrainLoss/PAIN{cmp_dim}x{cmp_dim}_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save Trained Model\n",
    "# ####################\n",
    "\n",
    "# # Model directory \n",
    "# directory = \"TrainedModels\"\n",
    "\n",
    "# # If the directory does not exist, create it\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# # Save trained model\n",
    "# PAIN.save(f'Trained_Models/PAIN{cmp_dim}x{cmp_dim}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply PAIN to all training inputs\n",
    "pred_train_out = PAIN.predict(noisy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print examples: training set\n",
    "################################\n",
    "\n",
    "# Create a 3 by 4 subplot handle\n",
    "fig, axes = plt.subplots(3, 4, figsize=(10, 8))\n",
    "axes      = axes.flatten()\n",
    "\n",
    "# Add title\n",
    "fig.suptitle('Application of PAIN Architecture\\n(MNIST Training Set)',fontsize=20,fontweight='bold', fontfamily='serif')\n",
    "\n",
    "# Shift window through training dataset \n",
    "sft_idx = 0\n",
    "\n",
    "# Plot noisy and decompressed realizations in each subplot\n",
    "for idx in range(4):\n",
    "    # Plot noisy\n",
    "    axes[idx].imshow(noisy_train[idx+sft_idx].reshape(cmp_dim,cmp_dim),cmap='gray')\n",
    "    axes[idx].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx].set_yticks([]) # Remove yticklabels\n",
    "    axes[idx].set_xlabel('â‡©',fontdict={'fontsize': 25, 'fontweight': 'bold', 'fontfamily': 'serif', 'color':'blue'})\n",
    "    \n",
    "    # Plot decompressed with PAIN\n",
    "    axes[idx+4].imshow(pred_train_out[idx+sft_idx].reshape(28,28),cmap='gray')\n",
    "    axes[idx+4].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx+4].set_yticks([]) # Remove yticklabels\n",
    "    \n",
    "    # Plot original\n",
    "    axes[idx+8].imshow(clean_train[idx+sft_idx].reshape(28,28),cmap='gray')\n",
    "    axes[idx+8].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx+8].set_yticks([]) # Remove yticklabels\n",
    "    \n",
    "# Set ylables \n",
    "# axes[0].set_ylabel(f'{cmp_dim} x {cmp_dim}\\n(Pre-Input)\\nCompressed',fontdict={'fontsize': 12, 'fontfamily': 'serif'})\n",
    "axes[0].set_ylabel(f'{cmp_dim} x {cmp_dim}\\n(Input)\\nCompressed & Noisy',fontdict={'fontsize': 12, 'fontfamily': 'serif', 'color':'blue'})\n",
    "axes[4].set_ylabel('28 x 28\\n(Output)\\nPAIN Reconstruction',fontdict={'fontsize': 12, 'fontfamily': 'serif', 'color':'blue'})\n",
    "axes[8].set_ylabel('28 x 28\\n(Original)\\nMNIST',fontdict={'fontsize': 12, 'fontfamily': 'serif'})\n",
    "\n",
    "# Adjust layout to decrease padding between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.25)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PAIN to all validation inputs\n",
    "pred_test_out = PAIN.predict(noisy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print examples: validation set\n",
    "################################\n",
    "\n",
    "# Create a 3 by 4 subplot handle\n",
    "fig, axes = plt.subplots(3, 4, figsize=(10, 8))\n",
    "axes      = axes.flatten()\n",
    "\n",
    "# Add title\n",
    "fig.suptitle('Application of PAIN Architecture\\n(MNIST Validation Set)',fontsize=20,fontweight='bold', fontfamily='serif')\n",
    "\n",
    "# Shift window through validation dataset \n",
    "sft_idx = 0\n",
    "\n",
    "# Plot noisy and decompressed realizations in each subplot\n",
    "for idx in range(4):\n",
    "    # Plot noisy\n",
    "    axes[idx].imshow(noisy_test[idx+sft_idx].reshape(cmp_dim,cmp_dim),cmap='gray')\n",
    "    axes[idx].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx].set_yticks([]) # Remove yticklabels\n",
    "    axes[idx].set_xlabel('â‡©',fontdict={'fontsize': 25, 'fontweight': 'bold', 'fontfamily': 'serif', 'color':'blue'})\n",
    "    \n",
    "    # Plot decompressed with PAIN\n",
    "    axes[idx+4].imshow(pred_test_out[idx+sft_idx].reshape(28,28),cmap='gray')\n",
    "    axes[idx+4].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx+4].set_yticks([]) # Remove yticklabels\n",
    "    \n",
    "    # Plot original\n",
    "    axes[idx+8].imshow(clean_test[idx+sft_idx].reshape(28,28),cmap='gray')\n",
    "    axes[idx+8].set_xticks([]) # Remove xticklabels\n",
    "    axes[idx+8].set_yticks([]) # Remove yticklabels\n",
    "    \n",
    "# Set ylables \n",
    "# axes[0].set_ylabel(f'{cmp_dim} x {cmp_dim}\\n(Pre-Input)\\nCompressed',fontdict={'fontsize': 12, 'fontfamily': 'serif'})\n",
    "axes[0].set_ylabel(f'{cmp_dim} x {cmp_dim}\\n(Input)\\nCompressed & Noisy',fontdict={'fontsize': 12, 'fontfamily': 'serif', 'color':'blue'})\n",
    "axes[4].set_ylabel('28 x 28\\n(Output)\\nPAIN Reconstruction',fontdict={'fontsize': 12, 'fontfamily': 'serif', 'color':'blue'})\n",
    "axes[8].set_ylabel('28 x 28\\n(Original)\\nMNIST',fontdict={'fontsize': 12, 'fontfamily': 'serif'})\n",
    "\n",
    "# Adjust layout to decrease padding between subplots\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.25)\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
